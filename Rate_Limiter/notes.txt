1.  Rate limiting algorithms are implemented, the resources that I have used to understand the rate limiting algorithms are here: 
    # https://www.youtube.com/watch?v=X5daFTDfy2g

2. The api gateways are the best places where we can plant the rate limiting endpoints since  the api gateways are used for the 
   authentication and routing of the requests coming into the system to the respectinve serving point. Load Balancer can also be good choise. 

3. So here at the authentication level we can identify the rate limiting since with the api key or the json web token we can identify the user and 
    can keep the track of the past request and current request for approving the request.

4. The token bucket algorithm fills the tokens to the bucket after every one third of the second. So accordingly quantity of refill tokens are calculated 
    depending upon the approved rate limiting rate. 

5. Using asynchronous programming to run both the processes of generating requests and approving request in a single process. The two background processes one 
   for generating the request and other for filling the bucket in case of the token bucket algorithm implementation.

6. Leaky bucket algorithm: In this algorithm the request is mimiked by the water flowing into the bucket and the approved rate is mimiked by the rate at which 
    water is leaking. If there is no space in the bucket the other incoming requests are rejected. However, in current implementation it can not handle this burst of requests 
    as in implementation logic the requests are not routed by the rate limiter like a load balancer rather they are approved to be processed by the server. 

7. In actual implementation of the leaky bucket, the bucket should block the request into the que and should pass it to the server at constant leak rate or approve rate. 

8. So the fixed window counter algorithm divides the time in windows of fixed time with allowed counts of requests in fixed window.

9. In the implementation of fixed window counter algorithm we mantain for evey user dictionary of the variables with three variables one is count of requests, other the current window of the user 
   (which may be old also based upon when the user has sent the request last time.) so we need to update the current window every time user sends a request. If the time at which user 
   has sent the request is in the current window it will not update the current window and will use the number of the counters to decide the requests to be processed. If the current window has expired 
   it will check and update the window and counter to zero.

10. One of the disadvantage of this algorithm is that it allows the burst of the request at the edges allowwing  double the allowed rate of requests.

11. For fixed window counter following videos were used to understand the algorithms: 
    a. https://www.youtube.com/watch?v=ms8UtuewgcQ&t=0s
    b. https://www.youtube.com/watch?v=wOi3TF9IbOQ

12. For the sliding window log rate limiting algorithm we do not have fixed window of the time instead we have a sliding time window. So 
    we can have infinite positions of this sliding window in a period of time greater than the size of this sliding window. So the algorithm says that 
    at any time sliding window the no of requests can not be more than the allowed requests in that window. This algorithm is improvement over 
    the fixed window algorithm which allowes more no. of allowed requests in case of the bursts of requests if comes at the edges of the window.

13. In implementation of the above algorithm every time a request comes we check if the sliding window is already full and we remove the old request logs and make space of the incoming request.

14. For this sliding window log rate limiting algorithm following youtube videos were used: 
    a. https://www.youtube.com/watch?v=iiSGsvg_Ams
    b. https://www.youtube.com/watch?v=iQKtqYue5cg